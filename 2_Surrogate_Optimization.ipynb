{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Surrogate optimization\n",
    "\n",
    "* Used for optimization of \"heavy\" functions (computationally complex, expensive to evaluate)\n",
    "* The objective function can be \"black box\"\n",
    "* Uses approximation of the \"heavy\" objective function\n",
    "* Takes into account quality of the approximation and uncertainty of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Optimization procedure:\n",
    "1. Build approximation $\\hat{f}(x)$ of the function $f(x)$ using available data.\n",
    "2. Choose a new point as an argmax of a criterion\n",
    "$$\n",
    "x_{new} = \\arg\\max\\limits_x a(x).\n",
    "$$\n",
    "3. Evaluate $f(x)$ at $x_{new}$.\n",
    "4. Update model $\\hat{f}(x)$ and go to step 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expected Improvement is one of the most widely used criteria\n",
    "\n",
    "$$\n",
    "EI(x) = \\mathbb{E}_{p(\\hat{f})} \\left [\\max(0, y_{min} - \\hat{f}) \\right ]\n",
    "$$\n",
    "where $\\mu(\\mathbf{x}), \\sigma(\\mathbf{x})$ are mean and variance of GP model at point $x$,\n",
    "$\\Phi(\\cdot)$ - cdf of standard normal distribution,\n",
    "$\\phi(\\cdot)$ - pdf of standard normal distribution.\n",
    "\n",
    "Usually logarithm of EI is used.\n",
    "\n",
    "![EI](EI_vs_logEI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of expected improvement\n",
    "\n",
    "$$\n",
    "EI = \\int_{-\\infty}^{y_{min}} (y_{min} - \\hat{y}) \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left (-\\frac{(\\hat{y} - \\mu)^2}{2 \\sigma^2} \\right ) d\\hat{y} = \\left |t = \\frac{\\hat{y} - \\mu}{\\sigma}, \n",
    "\\quad z = \\frac{y_{min} - \\mu}{\\sigma}\\right | = \\\\\n",
    "\\int_{-\\infty}^z (y - \\mu - \\sigma t)\\phi(t) dt = (y - \\mu) \\Phi(z) - \\sigma \\int_{-\\infty}^z t \\phi(t) dt\n",
    "$$\n",
    "$$\n",
    "\\int_{-\\infty}^z t\\phi(t)dt = \\int_{-\\infty}^z \\frac{1}{\\sqrt{2 \\pi}}t e^{-t^2 / 2}dt = \\int\\limits_{+\\infty}^{\\dfrac{z^2}{2}}\\dfrac{1}{\\sqrt{2\\pi}}e^{-x}dx = -\\dfrac{1}{\\sqrt{2\\pi}}e^{\\dfrac{z^2}{2}} = - \\phi(z)\n",
    "$$\n",
    "\n",
    "Finally we get:\n",
    "\n",
    "$$\n",
    "\\Rightarrow EI(\\mathbf{x}) = (y_{min} - \\mu(\\mathbf{x})) \\Phi\\left ( \\frac{y_{min} - \\mu(\\mathbf{x})}{\\sigma(\\mathbf{x})} \\right ) + \\sigma(\\mathbf{x}) \\phi \\left ( \\frac{y_{min} - \\mu(\\mathbf{x})}{\\sigma(\\mathbf{x})}\\right ),\n",
    "$$\n",
    "where $\\mu(\\mathbf{x})$ is the posterior mean at $\\mathbf{x}$, $\\sigma(\\mathbf{x})$ is the posterior variance at $\\mathbf{x}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimization of criterion\n",
    "\n",
    "Any optimization algorithm could be used.\n",
    "\n",
    "Here we use multi-start with L-BFGS optimization algorithm\n",
    "\n",
    "Multi-start procedure:\n",
    "1. Generate initial set of points $x_1, \\ldots, x_n$. Calculate criterion at each point to obtain $(a(x_1), \\ldots, a(x_n))$.\n",
    "2. Choose $k$ points with the smallest values of criterion.\n",
    "3. Using each point as an initial point run the optimization algorithm (L-BFGS) and obtain $k$ optimization results.\n",
    "4. From all optimization results choose the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### L-BFGS \n",
    "\n",
    "It's a quasi-Newton method of optimization based on the second order Taylor expansion\n",
    "$$\n",
    "f(x_k + p) \\approx f(x_k) + \\nabla f^T(x_k) p + \\frac12 p^T \\mathbf{H}p,\n",
    "$$\n",
    "$$\n",
    "p = -\\mathbf{H}^{-1}\\nabla f^T(x_k) \\approx -\\mathbf{B}_k^{-1} \\nabla f^T(x_k),\n",
    "$$\n",
    "where $\\mathbf{B}_k$ is an approximation of the Hessian $\\mathbf{H}$.\n",
    "\n",
    "Approximation $\\mathbf{B}_k$ is updated at every step by the following rule:\n",
    "$$\n",
    "\\mathbf{B}_{k + 1} = \\mathbf{B}_k - \\frac{\\mathbf{B}_k s_k s_k^T \\mathbf{B}_k}{s_k^T \\mathbf{B}_k s_k} + \\frac{y_k y_k^T}{y_k^T s_k},\n",
    "$$\n",
    "where $s_k = x_{k + 1} - x_k$, $y_k = \\nabla f(x_{k + 1}) - \\nabla f(x_k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from utility import EngineeringModel\n",
    "\n",
    "import xgboost\n",
    "\n",
    "import GPy\n",
    "\n",
    "import bayes_opt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and blackbox model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "disk_model = pickle.load(open(\"disk_model.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points = np.loadtxt('surrogate_data/disk_points.csv', delimiter=',')[:, [0, 1, 2, 3, 6, 7]]\n",
    "values = np.loadtxt('surrogate_data/disk_values.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implement multi-start optimization procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_new_point(model, lower_bounds, upper_bounds, \n",
    "                  data=None, multistart=10, criterion='ei', k=1, random_state=None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        model - GP model of the objective function\n",
    "        lower_bounds, upper_bounds - array-like, lower and upper bounds of x\n",
    "        data - tuple(x_training, y_training)\n",
    "        multistart - number of multistart runs\n",
    "        criterion - aqcuisition function, by default log EI\n",
    "        k - parameter of the LowerConfidenceBound function\n",
    "        random_state - np.random.RandomState\n",
    "        \n",
    "    Returns\n",
    "        tuple - argmin of the objective function and min value of the objective \n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState()\n",
    "\n",
    "    lower_bounds = np.array(lower_bounds).reshape(1, -1)\n",
    "    upper_bounds = np.array(upper_bounds).reshape(1, -1)\n",
    "    \n",
    "    # 1. Generate inital X points (number of points == multistart) in [lower_bounds, upper_bounds]\n",
    "    random_initial_points = np.random.rand(multistart, len(lower_bounds)) * (upper_bounds - lower_bounds) + lower_bounds\n",
    "\n",
    "    def objective(x):\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        mean_values, variance = model.predict(x)\n",
    "        std_values = np.sqrt(variance)\n",
    "        if criterion == 'ei':\n",
    "            return -bayes_opt.log_expected_improvement(mean_values, std_values, data[1].min())\n",
    "        elif criterion == 'lcb':\n",
    "            return bayes_opt.lcb(mean_values, std_values, params)\n",
    "        else:\n",
    "            raise NotImplementedError('Criterion is not implemented!')\n",
    "\n",
    "    criterion_value = objective(random_initial_points)\n",
    "    \n",
    "    # 2. From each points from x_random run L-BFGS optimization algorithm, \n",
    "    #    choose the best result and return it\n",
    "    #    Use function minimize: minimize(objective, x_init, method='L-BFGS-B',\n",
    "    #                                    bounds=np.vstack((lb, ub)).T)\n",
    "    #    it returns object with fields 'fun' - optimum function value, 'x' - argmin.\n",
    "    \n",
    "    best_result = None\n",
    "    best_value = np.inf\n",
    "    for random_point in random_initial_points:\n",
    "        result = minimize(objective, random_point, method='L-BFGS-B',\n",
    "                          bounds=np.vstack((lower_bounds, upper_bounds)).T)\n",
    "        if result.fun < best_value:\n",
    "            best_value = result.fun\n",
    "            best_result = result\n",
    "    \n",
    "    return best_result.x, best_result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_training_sample_size = 20\n",
    "training_points = points[:initial_training_sample_size, :]\n",
    "training_values = values[:initial_training_sample_size, [0]] + 40 * values[:initial_training_sample_size, [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  79.13775675  133.82755135  162.44479622  190.74132703   35.80336811\n",
      "   35.80336811]\n",
      "[-3.32970976]\n",
      "[[ 31.06276516]\n",
      " [ 37.08819389]\n",
      " [ 35.71701098]\n",
      " [ 29.34268446]\n",
      " [ 31.02679453]\n",
      " [ 27.98023401]\n",
      " [ 33.76900553]\n",
      " [ 30.10790989]\n",
      " [ 35.9296632 ]\n",
      " [ 32.69274313]\n",
      " [ 32.37306474]\n",
      " [ 35.43993617]\n",
      " [ 34.80902073]\n",
      " [ 30.42322288]\n",
      " [ 34.05891345]\n",
      " [ 32.3389929 ]\n",
      " [ 32.32388818]\n",
      " [ 29.82280876]\n",
      " [ 33.76418261]\n",
      " [ 32.45551863]]\n"
     ]
    }
   ],
   "source": [
    "lower_bounds = [10, 120, 150, 170, 4, 4]\n",
    "upper_bounds = [110, 140, 168, 200, 50, 50]\n",
    "kernel = GPy.kern.RBF(input_dim=len(lower_bounds), variance=0.5, lengthscale=0.1)\n",
    "model = GPy.models.GPRegression(training_points, training_values, kernel)\n",
    "new_point, new_value = get_new_point(model, lower_bounds, upper_bounds, \n",
    "                                     data=(training_points, training_values), \n",
    "                                     random_state=np.random.RandomState(42))\n",
    "print(new_point)\n",
    "print(new_value)\n",
    "print(training_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimization_step(training_points, training_values, \n",
    "                      kernel, objective, \n",
    "                      lower_bounds=None, upper_bounds=None, \n",
    "                      criterion='ei', k=1):\n",
    "    model = GPy.models.GPRegression(training_points, training_values, kernel)\n",
    "    model.optimize_restarts(num_restarts=10, verbose=False)\n",
    "\n",
    "    new_point, criterion_value = get_new_point(model, data=(training_points, training_values), \n",
    "                                           lower_bounds=lower_bounds, upper_bounds=upper_bounds, \n",
    "                                           criterion=criterion, k=k)\n",
    "\n",
    "    new_point = new_point.reshape(1, -1)\n",
    "    training_points = np.vstack([training_points, new_point])\n",
    "    training_values = np.vstack([training_values, np.asarray(objective(new_point)).reshape(1, -1)])\n",
    "    return training_points, training_values, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Rotating disk problem\n",
    "\n",
    "We want to optimize the shape of a rotating disk inside an aircraft engine:\n",
    "\n",
    "![Engine](images/engine_disk.png)\n",
    "\n",
    "There are 6 parameters to optimize with 3 parameters fixed. \n",
    "\n",
    "![Engine](images/rotating_disk.png)\n",
    "\n",
    "See more details on the problem at \n",
    "1. Zaytsev, A. and Burnaev, E., 2017. Large scale variable fidelity surrogate modeling. Annals of Mathematics and Artificial Intelligence, pp.1-20.\n",
    "\n",
    "We thank DATADVANCE company for making the data available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "m, u_{max} &\\rightarrow \\min_{r_1, \\ldots, r_6, t_1, t_3, t_5}, \\\\\n",
    "10 &\\leq r_1 \\leq 110, 120 \\leq r_2 \\leq 140, \\nonumber \\\\\n",
    "150 &\\leq r_3 \\leq 168, 170 \\leq r_4 \\leq 200, \\nonumber \\\\\n",
    "4 &\\leq t_1 \\leq 50, 4 \\leq t_3 \\leq 50, \\nonumber \\\\\n",
    "r_5 &= 210, r_6 = 230, t_5 = 32. \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "To handle two objectives we minimize instead $m + 40 u_{max}$ with multiplier $40$ added to keep the scale same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_objective(point):\n",
    "  if len(np.shape(point)) == 1:\n",
    "    point = np.reshape(points, (1, -1))\n",
    "  return disk_model.evaluate(point, 0) + 40 * disk_model.evaluate(point, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.98023401\n",
      "[ 35.39561164]\n"
     ]
    }
   ],
   "source": [
    "updated_points, updated_values, model = optimization_step(training_points, training_values, \n",
    "                  kernel, objective, \n",
    "                  lower_bounds=lower_bounds, upper_bounds=upper_bounds, \n",
    "                  criterion='ei', k=1)\n",
    "\n",
    "print(np.min(updated_values[:-1]))\n",
    "print(updated_values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 32.12305909]\n",
      "[ 30.21099452]\n",
      "[ 31.70526742]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\User\\Anaconda2\\envs\\py36\\lib\\site-packages\\GPy\\kern\\src\\rbf.py:35: RuntimeWarning:overflow encountered in square\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 32.49735151]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\User\\Anaconda2\\envs\\py36\\lib\\site-packages\\paramz\\transformations.py:109: RuntimeWarning:overflow encountered in expm1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 31.94925005]\n",
      "[ 32.49735151]\n",
      "[ 28.8532991]\n",
      "[ 30.82343487]\n",
      "[ 33.34987286]\n",
      "[ 32.6790313]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\User\\Anaconda2\\envs\\py36\\lib\\site-packages\\GPy\\kern\\src\\stationary.py:160: RuntimeWarning:overflow encountered in true_divide\n",
      " C:\\Users\\User\\Anaconda2\\envs\\py36\\lib\\site-packages\\GPy\\kern\\src\\rbf.py:38: RuntimeWarning:invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 31.94925005]\n",
      "[ 25.44285067]\n",
      "[ 30.87237541]\n",
      "[ 29.22704416]\n",
      "[ 26.93620404]\n",
      "[ 30.86258997]\n",
      "[ 26.631617]\n",
      "[ 29.73437996]\n",
      "[ 28.43807819]\n",
      "[ 26.21156685]\n",
      "[ 25.60993402]\n",
      "[ 25.78223966]\n",
      "[ 27.78509161]\n",
      "[ 31.55508977]\n",
      "[ 31.21752904]\n",
      "[ 28.79678673]\n",
      "[ 25.78530749]\n",
      "[ 26.98244944]\n",
      "[ 27.50634013]\n",
      "[ 25.32215392]\n",
      "[ 25.32537176]\n",
      "[ 25.32045077]\n",
      "[ 38.35309687]\n",
      "[ 26.06991914]\n",
      "[ 27.46315217]\n",
      "[ 26.72199639]\n",
      "[ 29.03316612]\n",
      "[ 27.36347944]\n",
      "[ 27.84897429]\n",
      "[ 27.57969788]\n",
      "[ 27.1419393]\n",
      "[ 26.54612328]\n",
      "[ 27.20631187]\n",
      "[ 25.82443411]\n",
      "[ 27.45316939]\n",
      "[ 29.56638243]\n",
      "[ 26.87164178]\n",
      "[ 26.43267441]\n",
      "[ 37.37417436]\n",
      "[ 27.16959469]\n"
     ]
    }
   ],
   "source": [
    "number_of_new_points = 50\n",
    "updated_points, updated_values = training_points, training_values\n",
    "for index in range(number_of_new_points):\n",
    "  updated_points, updated_values, model = optimization_step(updated_points, updated_values, \n",
    "                  kernel, objective, \n",
    "                  lower_bounds=lower_bounds, upper_bounds=upper_bounds, \n",
    "                  criterion='ei', k=1)\n",
    "  print(updated_values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_index = np.argmin(training_values)\n",
    "start_point = training_points[[min_index], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfgs_result = minimize(evaluate_objective, start_point, method='L-BFGS-B',\n",
    "                       bounds=np.vstack((lower_bounds, upper_bounds)).T, \n",
    "                       callback=evaluate_objective, options={'maxiter' : 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  34.57  ,  123.274 ,  160.2834,  194.513 ,   20.169 ,    5.817 ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x167855228d0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFZwLgZlZwbkQmJkVnAuBmVnB/X+zTeleHgwSmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x167855c32e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([np.min(updated_values[:x]) for x in range(1, len(updated_values))])\n",
    "plt.plot([initial_training_sample_size, initial_training_sample_size],  \n",
    "            [np.min(updated_values), np.max(updated_values)], color='m')\n",
    "plt.xlabel('Point number')\n",
    "plt.ylabel('Current min value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hyperparmeters tuning\n",
    "\n",
    "* Almost all machine learning have hyperparameters\n",
    "* Quality of the model depends on the hyperparameters\n",
    "* Quality estimation for one set of hyperparameters can take long time\n",
    "* => Bayesian optimization can be used for hyperparameters tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Bayesian optimization for hyperparameter tuning\n",
    "\n",
    "Objective function to optimize\n",
    "* Takes hyperparameters as input\n",
    "* Builds a model (maybe several times in case of cross-validation)\n",
    "* Calculates and returns model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### House pricing dataset\n",
    "\n",
    "In this task you need to predict House Sale Price. There are 25 numerical input features like lot area, overall condition rating, house quality, number of kitchens and so on (there were a lot of categorical variables which we removed in this example for simplicity).\n",
    "\n",
    "We are going to tune XGBoost parameters using Bayesian Optimization to obtain more accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\User\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning:From version 0.21, test_size will always complement train_size unless both are specified.\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('house_pricing.csv')\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We implement `model_error_cv()` function that will be our objective function.  \n",
    "We are going to use RBF kernel in our Bayesian Optimization, the result of optimization will be continuous variables,\n",
    "so we need to preprocess parameters - cast integer parameters to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def wrap_parameters(parameters, scaler=None):\n",
    "    if scaler:\n",
    "        parameters = scaler.transform(parameters)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def unwrap_parameters(parameters, scaler=None):\n",
    "    if scaler:\n",
    "        parameters = scaler.inverse_transform(parameters)\n",
    "    p = [int(parameters[0]), parameters[1], int(parameters[2]),\n",
    "         max(0, min(parameters[3], 1))]\n",
    "    return p\n",
    "\n",
    "\n",
    "def model_error_cv(parameters, X, y, scaler=None):\n",
    "    errors = []\n",
    "    for p in parameters:\n",
    "        p = unwrap_parameters(p, scaler)\n",
    "        model = xgboost.XGBRegressor(max_depth=p[0],\n",
    "                                     learning_rate=p[1],\n",
    "                                     n_estimators=p[2],\n",
    "                                     subsample=p[3],\n",
    "                                     )\n",
    "\n",
    "        score = cross_val_score(model, X, y, cv=3).mean()\n",
    "        errors.append(score)\n",
    "    return np.array(errors).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We scale the parameters using StandardScaler() from sklearn - it is nice to have all the parameters with unit variance and mean zero\n",
    "when using RBF kernel as it is easier to tune lengthscale parameters, because these parameters depend on the range of input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# xgboost params: max_depth, learning_rate, n_estimators, subsample\n",
    "lower_bound = np.array([1, 0.001, 100, 0.2]).reshape(1, -1)\n",
    "upper_bound = np.array([6, 0.1, 1000, 1]).reshape(1, -1)\n",
    "\n",
    "np.random.seed(42)\n",
    "n_init_points = 10\n",
    "initial_parameters = np.random.rand(n_init_points, len(lower_bound)) * (upper_bound - lower_bound) + lower_bound\n",
    "initial_errors = -model_error_cv(initial_parameters, X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(initial_parameters)\n",
    "lower_bound = scaler.transform(lower_bound)\n",
    "upper_bound = scaler.transform(upper_bound)\n",
    "initial_parameters = wrap_parameters(initial_parameters, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It is also nice idea to explicitly constrain lengthscale parameter - it shouldn't be much larger than distance between points in the training set, it shouldn't be much smaller than the distance between points in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: reconstraining parameters GP_regression.rbf.lengthscale\n",
      "\n",
      "Name : GP regression\n",
      "Objective : 3.8216262628900273\n",
      "Number of Parameters : 3\n",
      "Number of Optimization Parameters : 3\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |            value  |  constraints  |  priors\n",
      "  \u001b[1mrbf.variance           \u001b[0;0m  |   0.418120652234  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale        \u001b[0;0m  |    2.31884566295  |  0.001,10.0   |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  0.0635911154505  |      +ve      |        \n",
      "  \u001b[1mindex\u001b[0;0m  |  GP_regression.rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                     2.31884566  |  0.001,10.0   |        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\User\\Anaconda2\\envs\\py36\\lib\\site-packages\\GPy\\core\\gp.py:87: UserWarning:Your kernel has a different input dimension 1 then the given X dimension 4. Be very sure this is what you want and you have not forgotten to set the right input dimenion in your kernel\n"
     ]
    }
   ],
   "source": [
    "kernel = GPy.kern.RBF(len(lower_bound), lengthscale=(upper_bound - lower_bound).min() / n_init_points, ARD=False)\n",
    "gp_model = GPy.models.GPRegression(initial_parameters, initial_errors, kernel=kernel)\n",
    "gp_model.rbf.lengthscale.constrain_bounded(0.001, 10)\n",
    "gp_model.optimize()\n",
    "print(gp_model)\n",
    "print(gp_model.rbf.lengthscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAF3CAYAAADXQiMjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16788a79358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New parameters: [2, 0.0501270130052077, 979, 0.88071952156181876], new error:\t0.8653525089786221\n",
      "best parameters: [2, 0.039110388501199224, 799, 0.57794806529623188], best error:\t0.8695530799939918\n",
      "  \u001b[1mindex\u001b[0;0m  |  GP_regression.rbf.lengthscale  |  constraints  |  priors\n",
      "  \u001b[1m[0]  \u001b[0;0m  |                     0.70482857  |  0.001,10.0   |        \n"
     ]
    }
   ],
   "source": [
    "budget = 40\n",
    "\n",
    "hyperparameters = initial_parameters\n",
    "errors = initial_errors\n",
    "error_history = [-initial_errors[:i].min() for i in range(1, n_init_points + 1)]\n",
    "objective = lambda x: -model_error_cv(x, X, y, scaler)\n",
    "for i in range(budget):\n",
    "    hyperparameters, errors, gp_model = bayes_opt.optimization_step(hyperparameters, errors, kernel, objective,\n",
    "                                                                    lb=lower_bound, ub=upper_bound)\n",
    "    error_history.append(-errors.min())\n",
    "    # Visualize\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "        \n",
    "    plt.xlabel(\"#iteration\")\n",
    "    plt.ylabel(\"R2\")\n",
    "    plt.plot(error_history)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"New parameters: {}, new error:\\t{}\\nbest parameters: {}, best error:\\t{}\".format(\n",
    "        unwrap_parameters(hyperparameters[-1], scaler), -errors[-1, 0],\n",
    "        unwrap_parameters(hyperparameters[errors.argmin()], scaler), -errors.min()))\n",
    "    print(gp_model.rbf.lengthscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
